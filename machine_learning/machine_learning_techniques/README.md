# Machine Learning Techniques

## Scaling

- Article on Medium: https://medium.com/@samir.silva12342/técnicas-de-aprendizado-de-máquina-scaling-d6fb0580dbd4

One of the most important transformations that needs to be applied to training and test datasets is feature scaling, i.e., scaling the data to limit its range of values. This is because, with some exceptions, machine learning algorithms do not perform well when input numerical attributes have different scales.

In this project, I mention and describe the most commonly used types of scaling in machine learning. Besides, I show an example of Python code using them.

### Featured Scalings

- Min-Max Scaling

<p align="center">
    <img width="400" src="https://github.com/Samirnunes/data-science/blob/main/machine_learning/machine_learning_techniques/scaling/images/min_max_formula.PNG" alt="Material Bread logo">
<p>

- Standard Scaling

<p align="center">
    <img width="400" src="https://github.com/Samirnunes/data-science/blob/main/machine_learning/machine_learning_techniques/scaling/images/std_formula.PNG" alt="Material Bread logo">
<p>

- Robust

<p align="center">
    <img width="400" src="https://github.com/Samirnunes/data-science/blob/main/machine_learning/machine_learning_techniques/scaling/images/robust_formula.PNG" alt="Material Bread logo">
<p>

## Regularization

- Article on Medium: https://medium.com/@samir.silva12342/técnicas-em-aprendizado-de-máquina-regularização-492e39433aca

To visualize the effects of L1 and L2 regularizations in a machine learning model, I’ve created a code based on my implementation from scratch of Linear Regression.
